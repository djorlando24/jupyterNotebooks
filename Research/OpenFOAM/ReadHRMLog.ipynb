{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cd52ee0",
   "metadata": {},
   "source": [
    "# OpenFOAM HRM Log Analysis\n",
    "\n",
    "This program extracts data from HRMFoam log files for analysis (i.e. net mass flux).\n",
    "    \n",
    "    @author Daniel Duke <daniel.duke@monash.edu>\n",
    "    @copyright (c) 2020 LTRAC\n",
    "    @license GPL-3.0+\n",
    "    @version 0.0.1\n",
    "    @date 02/11/2022\n",
    "        __   ____________    ___    ______\n",
    "       / /  /_  ____ __  \\  /   |  / ____/\n",
    "      / /    / /   / /_/ / / /| | / /\n",
    "     / /___ / /   / _, _/ / ___ |/ /_________\n",
    "    /_____//_/   /_/ |__\\/_/  |_|\\__________/\n",
    "\n",
    "    Laboratory for Turbulence Research in Aerospace & Combustion (LTRAC)\n",
    "    Monash University, Australia\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78915737",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load modules\n",
    "import numpy as np\n",
    "import glob, copy, gzip, natsort, tqdm, os\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcd57dab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read HRMFoam Log file, and extract key parameters in log at each iteration such as mass fluxes.\n",
    "def read_logfile(logFile):\n",
    "    time = []\n",
    "    data = {}\n",
    "    unit = {}\n",
    "    \n",
    "    print(\"Scanning \"+logFile+\"...\")\n",
    "    \n",
    "    with gzip.open(logFile,'r') as F:\n",
    "        Nlines=len(F.readlines())\n",
    "    \n",
    "    with gzip.open(logFile,'r') as F:\n",
    "        print(\"Reading data...\")\n",
    "        pbar = tqdm.tqdm(total=Nlines)\n",
    "        \n",
    "        l=F.readline(); n=1; m=0\n",
    "        while n<Nlines:\n",
    "            \n",
    "            if (not b'Time =' in l) or (b'ClockTime' in l):\n",
    "                # keep looping until we see 'Time =' string\n",
    "                # make exception for the ExecutionTime/ClockTime string at end of run - ignore it\n",
    "                l=F.readline(); n+=1\n",
    "                \n",
    "            else:\n",
    "                # Begin iteration block\n",
    "                pbar.update(n-m); m=n\n",
    "                # Record the time for this block\n",
    "                time.append(float(l.decode('ascii').split('=')[1]))\n",
    "                # Next line\n",
    "                l=F.readline(); n+=1\n",
    "\n",
    "                # Keep going until the next 'Time =' string indicating a new iteration\n",
    "                # Make an exception for the 'Net mass flux' string which has 'Time' in it\n",
    "                while (not b'Time =' in l) or (b'Net mass flux' in l):\n",
    "\n",
    "                    # Pressure/velocity data string\n",
    "                    if b' is ' in l:\n",
    "                        # Break apart this string by the word 'is' and the units brackets\n",
    "                        s = l.decode('ascii').strip().replace('is','[').replace(']','[').split('[')\n",
    "                        # remove leading and trailing whitespace\n",
    "                        s = [ ss.strip() for ss in s ]\n",
    "                        # Break apart each variable into name, value and units\n",
    "                        for i in range(0,len(s)-2,3):\n",
    "                            if s[i] in data.keys(): # not first time\n",
    "                                data[s[i]].append(float(s[i+1]))\n",
    "                            else: # first time\n",
    "                                data[s[i]]=[float(s[i+1])]\n",
    "                                unit[s[i]]=s[i+2]\n",
    "\n",
    "                    # Mass fluxes data string\n",
    "                    elif b' at ' in l:\n",
    "                        # Break apart this string by the = sign\n",
    "                        s = l.decode('ascii').strip().split('=')\n",
    "                        # remove leading and trailing whitespace\n",
    "                        s = [ ss.strip() for ss in s ]\n",
    "                        if(len(s)>1):\n",
    "                            if s[0] in data.keys(): # not first time\n",
    "                                data[s[0]].append(float(s[1]))\n",
    "                            else:\n",
    "                                data[s[0]]=[float(s[1])]\n",
    "                                unit[s[0]]=''\n",
    "\n",
    "                    elif b'Net mass flux' in l:\n",
    "                         # Break apart this string by the = sign\n",
    "                        s = l.decode('ascii').strip().split('=')\n",
    "                        # remove leading and trailing whitespace\n",
    "                        s = [ ss.strip() for ss in s ]\n",
    "                        if 'Net mass flux' in data.keys(): # not first time\n",
    "                            data['Net mass flux'].append(float(s[-1]))\n",
    "                        else:\n",
    "                            data['Net mass flux']=[float(s[-1])]\n",
    "                            unit['Net mass flux']=''\n",
    "                    \n",
    "                    elif n>=Nlines: break # detect premature EoF\n",
    "                    \n",
    "                    l=F.readline(); n+=1\n",
    "                    \n",
    "            # end iteration block\n",
    "            \n",
    "    pbar.close()\n",
    "    \n",
    "    # Convert data to NumPy Arrays\n",
    "    for k in data.keys():\n",
    "        data[k] = np.array(data[k])\n",
    "    time=np.array(time)\n",
    "    \n",
    "    return time, data, unit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42eb6724",
   "metadata": {},
   "source": [
    "## Main program\n",
    "Read logs and write them to a HDF5 file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "beb0d775",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "topLevel = \"/mnt/internal-hdd/2021_pmdi/newGeomTrial/postProcessing/massFlux/convergence_134a15pcEtOH/\"\n",
    "case = \"ures\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f906970",
   "metadata": {},
   "outputs": [],
   "source": [
    "topLevel = \"/mnt/internal-hdd/2021_pmdi/newGeomTrial/postProcessing/massFlux/ures/\"\n",
    "case = \"134a\" #15pcEtOH\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3795d07c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning /mnt/internal-hdd/2021_pmdi/newGeomTrial/postProcessing/massFlux/ures/134a/log.HRMFoamLESStatic-writePsi2Phase.1.gz...\n",
      "Reading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████████████████████████████████████████████████▉                                      | 1582522/2791330 [00:05<00:03, 350328.93it/s]"
     ]
    }
   ],
   "source": [
    "logFiles = topLevel + case + \"/*\"\n",
    "outputFile = topLevel + case + \".h5\"\n",
    "\n",
    "# Read all log files and write to HDF5\n",
    "with h5py.File(outputFile,'w') as H:\n",
    "    for logFile in natsort.natsorted(glob.glob(logFiles)):\n",
    "        \n",
    "        time,data,unit = read_logfile(logFile)\n",
    "        \n",
    "        G=H.create_group(os.path.basename(logFile))\n",
    "        t_=G.create_dataset('time',data=time,compression='gzip')\n",
    "        t_.attrs['unit']='s'\n",
    "        for k in data.keys():\n",
    "            d_=G.create_dataset(k,data=data[k],compression='gzip')\n",
    "            d_.attrs['unit']=unit[k]\n",
    "            \n",
    "        print(\"Wrote %i variables over %i iterations to %s\" % (len(data.keys()),len(time),G.name))\n",
    "        print(\"\")\n",
    "\n",
    "print(\"Finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6392479c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
