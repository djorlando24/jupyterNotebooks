{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cd52ee0",
   "metadata": {},
   "source": [
    "# OpenFOAM HRM Log Analysis\n",
    "\n",
    "This program extracts data from HRMFoam log files for analysis (i.e. net mass flux).\n",
    "    \n",
    "    @author Daniel Duke <daniel.duke@monash.edu>\n",
    "    @copyright (c) 2020 LTRAC\n",
    "    @license GPL-3.0+\n",
    "    @version 0.0.1\n",
    "    @date 02/11/2022\n",
    "        __   ____________    ___    ______\n",
    "       / /  /_  ____ __  \\  /   |  / ____/\n",
    "      / /    / /   / /_/ / / /| | / /\n",
    "     / /___ / /   / _, _/ / ___ |/ /_________\n",
    "    /_____//_/   /_/ |__\\/_/  |_|\\__________/\n",
    "\n",
    "    Laboratory for Turbulence Research in Aerospace & Combustion (LTRAC)\n",
    "    Monash University, Australia\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78915737",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load modules\n",
    "import numpy as np\n",
    "import glob, copy, gzip, natsort, tqdm, os\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcd57dab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read HRMFoam Log file, and extract key parameters in log at each iteration such as mass fluxes.\n",
    "def read_logfile(logFile):\n",
    "    time = []\n",
    "    data = {}\n",
    "    unit = {}\n",
    "    \n",
    "    print(\"Scanning \"+logFile+\"...\")\n",
    "    \n",
    "    with gzip.open(logFile,'r') as F:\n",
    "        Nlines=len(F.readlines())\n",
    "    \n",
    "    with gzip.open(logFile,'r') as F:\n",
    "        print(\"Reading data...\")\n",
    "        pbar = tqdm.tqdm(total=Nlines)\n",
    "        \n",
    "        l=F.readline(); n=1; m=0\n",
    "        while n<Nlines:\n",
    "            \n",
    "            if (not b'Time =' in l) or (b'ClockTime' in l):\n",
    "                # keep looping until we see 'Time =' string\n",
    "                # make exception for the ExecutionTime/ClockTime string at end of run - ignore it\n",
    "                l=F.readline(); n+=1\n",
    "                \n",
    "            else:\n",
    "                # Begin iteration block\n",
    "                pbar.update(n-m); m=n\n",
    "                # Record the time for this block\n",
    "                time.append(float(l.decode('ascii').split('=')[1]))\n",
    "                # Next line\n",
    "                l=F.readline(); n+=1\n",
    "\n",
    "                # Keep going until the next 'Time =' string indicating a new iteration\n",
    "                # Make an exception for the 'Net mass flux' string which has 'Time' in it\n",
    "                while (not b'Time =' in l) or (b'Net mass flux' in l):\n",
    "\n",
    "                    # Pressure/velocity data string\n",
    "                    # Make exception for some error codes\n",
    "                    if (b' is ' in l) and (not b'First token' in l):\n",
    "                        # Break apart this string by the word 'is' and the units brackets\n",
    "                        s = l.decode('ascii').strip().replace('is','[').replace(']','[').split('[')\n",
    "                        # remove leading and trailing whitespace\n",
    "                        s = [ ss.strip() for ss in s ]\n",
    "                        # Break apart each variable into name, value and units\n",
    "                        for i in range(0,len(s)-2,3):\n",
    "                            if s[i] in data.keys(): # not first time\n",
    "                                data[s[i]].append(float(s[i+1]))\n",
    "                            else: # first time\n",
    "                                data[s[i]]=[float(s[i+1])]\n",
    "                                unit[s[i]]=s[i+2]\n",
    "\n",
    "                    # Mass fluxes data string\n",
    "                    elif b' at ' in l:\n",
    "                        # Break apart this string by the = sign\n",
    "                        s = l.decode('ascii').strip().split('=')\n",
    "                        # remove leading and trailing whitespace\n",
    "                        s = [ ss.strip() for ss in s ]\n",
    "                        if(len(s)>1):\n",
    "                            if s[0] in data.keys(): # not first time\n",
    "                                data[s[0]].append(float(s[1]))\n",
    "                            else:\n",
    "                                data[s[0]]=[float(s[1])]\n",
    "                                unit[s[0]]=''\n",
    "\n",
    "                    elif b'Net mass flux' in l:\n",
    "                         # Break apart this string by the = sign\n",
    "                        s = l.decode('ascii').strip().split('=')\n",
    "                        # remove leading and trailing whitespace\n",
    "                        s = [ ss.strip() for ss in s ]\n",
    "                        if 'Net mass flux' in data.keys(): # not first time\n",
    "                            data['Net mass flux'].append(float(s[-1]))\n",
    "                        else:\n",
    "                            data['Net mass flux']=[float(s[-1])]\n",
    "                            unit['Net mass flux']=''\n",
    "                    \n",
    "                    elif n>=Nlines: break # detect premature EoF\n",
    "                    \n",
    "                    l=F.readline(); n+=1\n",
    "                    \n",
    "            # end iteration block\n",
    "            \n",
    "    pbar.close()\n",
    "    \n",
    "    # Convert data to NumPy Arrays\n",
    "    for k in data.keys():\n",
    "        data[k] = np.array(data[k])\n",
    "    time=np.array(time)\n",
    "    \n",
    "    # Remove empty keys\n",
    "    if '' in data.keys():\n",
    "        del data['']\n",
    "    \n",
    "    return time, data, unit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42eb6724",
   "metadata": {},
   "source": [
    "## Main program\n",
    "Read logs and write them to a HDF5 file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84e9b1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCase(logFiles, outputFile):\n",
    "\n",
    "    # Read all log files and write to HDF5\n",
    "    with h5py.File(outputFile,'w') as H:\n",
    "        for logFile in natsort.natsorted(glob.glob(logFiles)):\n",
    "\n",
    "            time,data,unit = read_logfile(logFile)\n",
    "\n",
    "            G=H.create_group(os.path.basename(logFile))\n",
    "            t_=G.create_dataset('time',data=time,compression='gzip')\n",
    "            t_.attrs['unit']='s'\n",
    "            for k in data.keys():\n",
    "                try:\n",
    "                    d_=G.create_dataset(k,data=data[k],compression='gzip')\n",
    "                    d_.attrs['unit']=unit[k]\n",
    "                except:\n",
    "                    print(data.keys())\n",
    "                    raise\n",
    "\n",
    "            print(\"Wrote %i variables over %i iterations to %s\" % (len(data.keys()),len(time),G.name))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9e2f9d",
   "metadata": {},
   "source": [
    "## Call main program once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb0d775",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# One run\n",
    "topLevel = \"/mnt/internal/2021_pmdi/newGeomTrial/postProcessing/massFlux/convergence_134a15pcEtOH/\"\n",
    "case = \"ures\"\n",
    "logFiles = topLevel + case + \"/*\"\n",
    "outputFile = topLevel + case + \".h5\"\n",
    "readCase(logFiles, outputFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f906970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One run\n",
    "topLevel = \"/mnt/internal/2021_pmdi/newGeomTrial/postProcessing/massFlux/ures/\"\n",
    "case = \"152a15pcEtOH\"\n",
    "logFiles = topLevel + case + \"/*\"\n",
    "outputFile = topLevel + case + \".h5\"\n",
    "readCase(logFiles, outputFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e7f69b",
   "metadata": {},
   "source": [
    "### Variable Geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3795d07c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Writing into /mnt/internal-hdd/2021_pmdi/newGeomTrial/postProcessing/massFlux/newGeomTrial/newGeomTrial_152a15pcEtOH.h5\n",
      "Scanning /mnt/internal-hdd/2021_pmdi/newGeomTrial/postProcessing/massFlux/newGeomTrial/noz1_152a15pcEtOH.txt.gz...\n",
      "Reading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████▉| 37342543/37342547 [01:43<00:00, 359224.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 14 variables over 866734 iterations to /noz1_152a15pcEtOH.txt.gz\n",
      "\n",
      "Scanning /mnt/internal-hdd/2021_pmdi/newGeomTrial/postProcessing/massFlux/newGeomTrial/noz2_152a15pcEtOH.txt.gz...\n",
      "Reading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████▉| 138692306/138692349 [06:50<00:00, 337504.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 14 variables over 3276508 iterations to /noz2_152a15pcEtOH.txt.gz\n",
      "\n",
      "Scanning /mnt/internal-hdd/2021_pmdi/newGeomTrial/postProcessing/massFlux/newGeomTrial/noz3_152a15pcEtOH.txt.gz...\n",
      "Reading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████▉| 32012840/32012856 [01:34<00:00, 338017.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 14 variables over 779342 iterations to /noz3_152a15pcEtOH.txt.gz\n",
      "\n",
      "Scanning /mnt/internal-hdd/2021_pmdi/newGeomTrial/postProcessing/massFlux/newGeomTrial/noz4_152a15pcEtOH.txt.gz...\n",
      "Reading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████▉| 27640672/27640693 [01:27<00:00, 316039.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 14 variables over 637098 iterations to /noz4_152a15pcEtOH.txt.gz\n",
      "\n",
      "Scanning /mnt/internal-hdd/2021_pmdi/newGeomTrial/postProcessing/massFlux/newGeomTrial/noz5_152a15pcEtOH.txt.gz...\n",
      "Reading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████▉| 36567019/36567039 [02:06<00:00, 289117.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 15 variables over 830771 iterations to /noz5_152a15pcEtOH.txt.gz\n",
      "\n",
      "Scanning /mnt/internal-hdd/2021_pmdi/newGeomTrial/postProcessing/massFlux/newGeomTrial/noz6_152a15pcEtOH.txt.gz...\n",
      "Reading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████▉| 210472660/210472695 [10:39<00:00, 328966.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 14 variables over 5123869 iterations to /noz6_152a15pcEtOH.txt.gz\n",
      "\n",
      "Scanning /mnt/internal-hdd/2021_pmdi/newGeomTrial/postProcessing/massFlux/newGeomTrial/noz7_152a15pcEtOH.txt.gz...\n",
      "Reading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████▉| 37052509/37052553 [01:42<00:00, 361086.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 14 variables over 886806 iterations to /noz7_152a15pcEtOH.txt.gz\n",
      "\n",
      "Scanning /mnt/internal-hdd/2021_pmdi/newGeomTrial/postProcessing/massFlux/newGeomTrial/noz8_152a15pcEtOH.txt.gz...\n",
      "Reading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████▉| 35904082/35904123 [01:37<00:00, 369360.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 14 variables over 858862 iterations to /noz8_152a15pcEtOH.txt.gz\n",
      "\n",
      "Scanning /mnt/internal-hdd/2021_pmdi/newGeomTrial/postProcessing/massFlux/newGeomTrial/noz9_152a15pcEtOH.txt.gz...\n",
      "Reading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████▉| 34664264/34664307 [01:33<00:00, 371228.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 14 variables over 803827 iterations to /noz9_152a15pcEtOH.txt.gz\n",
      "\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "topLevel = \"/mnt/internal-hdd/2021_pmdi/newGeomTrial/postProcessing/massFlux/newGeomTrial/\"\n",
    "for p in ['134a','152a','1234ze','134a15pcEtOH','152a15pcEtOH','1234ze15pcEtOH']:\n",
    "    \n",
    "    logFiles = topLevel + \"noz?_\" + p + \".txt.gz\"\n",
    "        \n",
    "    outputFile = topLevel + \"newGeomTrial_\"  + p + \".h5\"\n",
    "    \n",
    "    if not os.path.isfile(outputFile):\n",
    "        print(\"-- Writing into \"+outputFile)\n",
    "        readCase(logFiles, outputFile)\n",
    "    \n",
    "print(\"Finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6392479c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
