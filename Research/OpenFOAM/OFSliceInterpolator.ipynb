{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fad2d3fc",
   "metadata": {},
   "source": [
    "# OpenFOAM Slice Analysis\n",
    "\n",
    "This program extracts data from Paraview slices of grids, interpolates them, and computes L2 norm, etc.\n",
    "    \n",
    "    @author Daniel Duke <daniel.duke@monash.edu>\n",
    "    @copyright (c) 2020 LTRAC\n",
    "    @license GPL-3.0+\n",
    "    @version 0.0.1\n",
    "    @date 08/11/2022\n",
    "        __   ____________    ___    ______\n",
    "       / /  /_  ____ __  \\  /   |  / ____/\n",
    "      / /    / /   / /_/ / / /| | / /\n",
    "     / /___ / /   / _, _/ / ___ |/ /_________\n",
    "    /_____//_/   /_/ |__\\/_/  |_|\\__________/\n",
    "\n",
    "    Laboratory for Turbulence Research in Aerospace & Combustion (LTRAC)\n",
    "    Monash University, Australia\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8884be12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load modules\n",
    "import numpy as np\n",
    "import glob, gzip, tqdm, os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce248368",
   "metadata": {},
   "source": [
    "X0 slices are computed by taking a plane parallel to the nozzle axis at the symmetry line of the domain.\n",
    "\n",
    "All other slices are computed by taking a plane normal to the nozzle axis at a fixed streamwise station.\n",
    "\n",
    "Computation process is the same for all planes:\n",
    "1. Take threshold yMean <= 0.99 (removing pure air regions)\n",
    "2. Transform geometry to ensure (0,0,0) is the middle of the nozzle exit for all grids\n",
    "3. Take a slice\n",
    "4. Compute a new field 'noz' which reflects which grid we are using\n",
    "5. Merge all datasets for noz1...noz9 and save this for a single fluid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93540326",
   "metadata": {},
   "source": [
    "## Function to read slice CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a40c0587",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_slice_csv(filename):\n",
    "    if filename[-3:].lower() == '.gz': fileReader=gzip.open\n",
    "    else: fileReader=open\n",
    "           \n",
    "    print(\"Scanning \"+filename+\"...\")\n",
    "    with fileReader(filename,'r') as F:\n",
    "        Nlines=len(F.readlines())\n",
    "    \n",
    "    with fileReader(filename,'r') as F:\n",
    "        print(\"Reading data...\")\n",
    "        varNames = F.readline().strip().replace('\"','').split(',')\n",
    "        data = np.ndarray((len(varNames),Nlines-1))\n",
    "        for n in tqdm.tqdm(range(Nlines-1)):\n",
    "            d = F.readline().strip().replace('\"','').split(',')\n",
    "            data[:,n] = [float(d_) for d_ in d]\n",
    "        \n",
    "    return data, varNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1279a00c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning /mnt/internal-hdd/2021_pmdi/newGeomTrial/postProcessing/convergence/conv_fromVtm.csv...\n",
      "Reading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 510712/510712 [00:14<00:00, 34182.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size: (66, 510712)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#topLevel = \"/mnt/internal-hdd/2021_pmdi/newGeomTrial/postProcessing/slices/\"\n",
    "topLevel = \"/mnt/internal-hdd/2021_pmdi/newGeomTrial/postProcessing/convergence/\"\n",
    "\n",
    "D,V=read_slice_csv(topLevel+\"conv_fromVtm.csv\")\n",
    "print(\"dataset size: \"+str(D.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec55b86",
   "metadata": {},
   "source": [
    "## Sort data combined in single CSV using a flag field\n",
    "if GroupDatasets was used in Paraview with some field being a flag to indicate which data points are from which grids, we can split them apart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a76fa49e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorting index [1] : 39067 gridpoints\n",
      "Sorting index [2] : 57278 gridpoints\n",
      "Sorting index [3] : 127523 gridpoints\n",
      "Sorting index [4] : 133630 gridpoints\n",
      "Sorting index [5] : 153214 gridpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:01<00:00,  4.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moved (66, 510712) -> (5, 66, 153214)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sortingKey = 'resolution'\n",
    "\n",
    "# Get the possible values of the sorting key and which column it is in.\n",
    "keyIndex = V.index(sortingKey)\n",
    "keyValues = np.unique(D[keyIndex,:])\n",
    "\n",
    "# Find the largest number of gridpoints for any possible sorting key value\n",
    "npts = 0\n",
    "nmin = np.inf\n",
    "kmin = None\n",
    "for k in keyValues:\n",
    "    n = np.sum(D[keyIndex,:]==k)\n",
    "    if n>npts:\n",
    "        npts=n\n",
    "    if n<nmin: \n",
    "        nmin=n\n",
    "        kmin=k\n",
    "    print(\"Sorting index [%i] : %i gridpoints\" %(k,n) )\n",
    "    \n",
    "# Move data to new array.\n",
    "Ds = np.ndarray((len(keyValues), len(V), npts))\n",
    "Ds[...] = np.nan\n",
    "for j in tqdm.tqdm(range(len(keyValues))):\n",
    "    i = D[keyIndex,:]==keyValues[j]\n",
    "    Ds[j, :, :np.sum(i)] = D[:, i]\n",
    "\n",
    "\n",
    "print(\"Moved %s -> %s\" % (D.shape, Ds.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020fe13d",
   "metadata": {},
   "source": [
    "## Interpolate data onto a uniform grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15f654fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.interpolate, scipy.spatial\n",
    "\n",
    "\n",
    "def interpolateFunction(d, xy_input_indices, xy_output, pbar=None):\n",
    "    \"\"\" Dan's function to run the interpolation on the last axis of a 2d array with the 1st axis\n",
    "    being independent variables.\"\"\"\n",
    "    \n",
    "    # Get coordinates of input data\n",
    "    valid = ~np.isnan(d[xy_input_indices[0],:]) # X is not NaN\n",
    "    xy_input = [ d[i,valid] for i in xy_input_indices ]\n",
    "    \n",
    "    # Precompute Delaunay triangulation - will be same for every variable.\n",
    "    # https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.Delaunay.html\n",
    "    points = scipy.spatial.Delaunay(np.transpose(np.array(xy_input)), furthest_site=False,\\\n",
    "                                    incremental=False, qhull_options=None)\n",
    "    \n",
    "    # Loop variables\n",
    "    interpolatedResult = []\n",
    "    for i in range(d.shape[0]): \n",
    "        if not i in xy_input_indices: # Interpolate data for non coord variable\n",
    "            #https://docs.scipy.org/doc/scipy/reference/generated/scipy.interpolate.LinearNDInterpolator.html            \n",
    "            fInt = scipy.interpolate.LinearNDInterpolator(points, d[i,valid], fill_value=np.nan, rescale=False)\n",
    "            interpolatedResult.append(fInt(xy_output[0], xy_output[1]))\n",
    "            \n",
    "        elif i == xy_input_indices[0]: # Copy coordinates directly\n",
    "            interpolatedResult.append(xy_output[0])\n",
    "        elif i == xy_input_indices[1]: # Copy coordinates directly\n",
    "            interpolatedResult.append(xy_output[1])\n",
    "        else:\n",
    "            raise IndexError\n",
    "            \n",
    "        if pbar is not None: pbar.update(d.shape[-1])\n",
    "        \n",
    "    return np.array(interpolatedResult)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9e51cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plane normal is X axis\n",
      "Interpolating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 50560620/50560620 [00:56<00:00, 893297.62it/s]\n"
     ]
    }
   ],
   "source": [
    "# Specify the variables containing the coordinates of grid points\n",
    "xv = \"Center:0\" ; yv = \"Center:1\" ; zv = \"Center:2\"\n",
    "xi = V.index(xv); yi = V.index(yv); zi = V.index(zv)\n",
    "\n",
    "# Use the lowest resolution grid as the basis for interpolation.\n",
    "j_lowest = np.where(keyValues==kmin)[0][0]\n",
    "X = Ds[j_lowest,xi,:]\n",
    "Y = Ds[j_lowest,yi,:]\n",
    "Z = Ds[j_lowest,zi,:]\n",
    "\n",
    "X = X[~np.isnan(X)]\n",
    "Y = Y[~np.isnan(Y)]\n",
    "Z = Z[~np.isnan(Z)]\n",
    "\n",
    "# Loop through X,Y,Z and figure out which to put in x and y\n",
    "# Presently we assume that the plane is in X, Y or Z normal axis\n",
    "# If it is tilted in all 3 axes we'd need to have a new coordinate system calculated/stored!\n",
    "if np.nanstd(X)==0:\n",
    "    xyz_input_indices = (yi,zi)\n",
    "    xyz_output = (Y,Z)\n",
    "    plane_norm = xv\n",
    "    print(\"Plane normal is X axis\")\n",
    "elif np.nanstd(Y)==0:\n",
    "    xyz_input_indices = (xi,zi)\n",
    "    xyz_output = (X,Z)\n",
    "    plane_norm = yv\n",
    "    print(\"Plane normal is Y axis\")\n",
    "elif np.nanstd(Z)==0:\n",
    "    xyz_input_indices = (xi,yi)\n",
    "    xyz_output = (X,Y)\n",
    "    plane_norm = zv\n",
    "    print(\"Plane normal is Z axis\")\n",
    "else:\n",
    "    raise ValueError(\"Error: plane is tilted in all axes, recalculate \"+xv)\n",
    "    \n",
    "# Make new array of smaller size\n",
    "Di = np.ndarray((len(keyValues), len(V), nmin))\n",
    "Di[...] = np.nan\n",
    "\n",
    "# Do interpolation for each grid\n",
    "print(\"Interpolating...\")\n",
    "pbar = tqdm.tqdm(total=np.product(Ds.shape))\n",
    "for j in range(len(keyValues)):\n",
    "    Di[j,...] = interpolateFunction(Ds[j,...], xyz_input_indices, xyz_output, pbar )\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc8099a",
   "metadata": {},
   "source": [
    "## Save the interpolated data for posterity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55818432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved.\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "with h5py.File(topLevel+\"conv_interpolated.h5\",'w') as H:\n",
    "    vds = H.create_dataset(\"Variables\",data=V)\n",
    "    vds.attrs['sortingKey']=sortingKey\n",
    "    H.create_dataset(\"Sorted data\",data=Ds,compression='gzip')\n",
    "    G=H.create_group(\"Interpolated data\")\n",
    "    G.create_dataset(\"coords\",data=xyz_output,compression='gzip')\n",
    "    G.create_dataset(\"data\",data=Di,compression='gzip')\n",
    "    G.attrs['plane_norm']=plane_norm\n",
    "print(\"saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc5087f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
