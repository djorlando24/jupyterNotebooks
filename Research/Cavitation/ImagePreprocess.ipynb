{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e37341b-4511-44c9-b619-edd232d9b1ff",
   "metadata": {},
   "source": [
    "# High speed imaging pre processing\n",
    "\n",
    "Load TIFF image sequence of spray data, etc, remove background and extract stable period for analysis.\n",
    "    \n",
    "    @author Daniel Duke <daniel.duke@monash.edu>\n",
    "    @copyright (c) 2024 LTRAC\n",
    "    @license GPL-3.0+\n",
    "    @version 0.0.1\n",
    "    @date 13/08/2024\n",
    "\n",
    "    Laboratory for Turbulence Research in Aerospace & Combustion (LTRAC)\n",
    "    Monash University, Australia\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e184a38-a546-4b95-9cc4-63cbb34ff24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pySciCam.pySciCam import ImageSequence # https://github.com/djorlando24/pySciCam\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import Parallel, delayed\n",
    "import numpy as np\n",
    "import scipy.integrate\n",
    "import time, os, gc\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bffc871-018a-4d0b-8bb8-f93a961b831e",
   "metadata": {},
   "source": [
    "## Load images to memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac084904-94e2-4488-beb7-d57a57c73b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directory where images come from.\n",
    "source_images = \"/Users/dduke/Desktop/sampleImaging/mountPoint/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3061348-11de-4539-b507-546b7d1c58c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOAD BACKGROUND\n",
      "Reading /Users/dduke/Desktop/sampleImaging/mountPoint/\n",
      "\tFound 149001 images with extension .tif\n",
      "\tPythonMagick thinks the bit depth is uint12\n",
      "\tReading files into memory...\n",
      "10 tasks on 10 processors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done   3 out of  10 | elapsed:    2.0s remaining:    4.6s\n",
      "[Parallel(n_jobs=10)]: Done   6 out of  10 | elapsed:    2.1s remaining:    1.4s\n",
      "[Parallel(n_jobs=10)]: Done  10 out of  10 | elapsed:    2.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 224.1 MiB in 2.3 sec\n",
      "\tData in memory:\t (1000, 408, 384)\n",
      "\tIntensity range:\t 0 to 53740 \t uint16\n",
      "\tArray size:\t298.8 MB\n",
      "\n",
      "LOAD EVENT TIME SEQUENCE\n",
      "Reading /Users/dduke/Desktop/sampleImaging/mountPoint/\n",
      "\tFound 149001 images with extension .tif\n",
      "\tPythonMagick thinks the bit depth is uint12\n",
      "\tReading files into memory...\n",
      "100 tasks on 10 processors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  52 tasks      | elapsed:   26.1s\n",
      "[Parallel(n_jobs=10)]: Done 100 out of 100 | elapsed:   44.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 5603.0 MiB in 98.1 sec\n",
      "\tData in memory:\t (25000, 408, 384)\n",
      "\tIntensity range:\t 0 to 54508 \t uint16\n",
      "\tArray size:\t7470.7 MB\n"
     ]
    }
   ],
   "source": [
    "# Load bkgnd\n",
    "print(\"LOAD BACKGROUND\")\n",
    "B=ImageSequence(source_images, IO_threads=4, dtype=np.uint16, frames=(0,1000))\n",
    "\n",
    "# Load event images in set range - can divide to chunk for ram limit\n",
    "find_steady_start=False#True\n",
    "find_steady_end=False\n",
    "\n",
    "fr0=25000#1000\n",
    "fr1=50000#25000\n",
    "\n",
    "print(\"\\nLOAD EVENT TIME SEQUENCE\")\n",
    "I=ImageSequence(source_images, IO_threads=4, dtype=np.uint16, frames=(fr0,fr1))\n",
    "\n",
    "# coordinate vectors\n",
    "y = np.arange(I.arr.shape[1])\n",
    "x = np.arange(I.arr.shape[2])\n",
    "t = np.arange(fr0,fr1)\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97bd681-4f92-4924-8cf6-f07ae10896a7",
   "metadata": {},
   "source": [
    "## Background removal\n",
    "This step is memory intensive as it requires conversion to 32bit float.\n",
    "The 16bit int data will be deleted when this step is complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8b8ba5-b944-404f-86f8-0e5d9e20d01a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Background removal...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1100 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done 3100 tasks      | elapsed:   10.6s\n",
      "[Parallel(n_jobs=-1)]: Done 5900 tasks      | elapsed:   21.2s\n",
      "[Parallel(n_jobs=-1)]: Done 9500 tasks      | elapsed:   38.5s\n"
     ]
    }
   ],
   "source": [
    "# Make the background reference image.\n",
    "bkgnd = np.nanmean(B.arr,axis=0).astype(np.float32)\n",
    "del B\n",
    "bkgnd[bkgnd<=0] = np.nan\n",
    "\n",
    "eps=1e-3 # divide-by-zero correction\n",
    "\n",
    "# A function to operate on a single frame. Returns float32 using auto typing\n",
    "# Convert transmission to extinction while removing background : ext = 1 - abs, abs = I_raw/I_bkgnd.\n",
    "def doBkgndRemoval(I_raw): return 1.0 - (I_raw / (bkgnd+eps))\n",
    "\n",
    "# Use multiple threads to speed up the floating point division calculation.\n",
    "print(\"Background removal...\")\n",
    "Ilist = Parallel(n_jobs=-1,verbose=1)(delayed(doBkgndRemoval)(I.arr[n,...]) for n in range(I.N))\n",
    "del I     # Remove original images to save memory.\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab86203-6dbf-4a0c-a70c-f9fee78cf206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert from list back to 3D array (using dstack)\n",
    "\n",
    "t_ = time.time()\n",
    "print(\"Converting to 3D array...\")\n",
    "Ib = np.dstack(Ilist)\n",
    "print(' - ',Ib.dtype)\n",
    "del Ilist # Remove original list to save memory.\n",
    "\n",
    "Ib = np.rollaxis(Ib,2,0) # Rearrange axes back to original form.\n",
    "print(Ib.shape);\n",
    "gc.collect();\n",
    "print(\" - elapsed time: %.1f s\" % (time.time()-t_));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92d92d4-d9dd-4632-b4c0-1fe9da7610a7",
   "metadata": {},
   "source": [
    "## Show some sample images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a68324-8d78-4bfb-b708-f448295f3a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure()\n",
    "plt.suptitle(\"Sample frames\\n\"+os.path.basename(source_images))\n",
    "some_frames = np.linspace(0,Ib.shape[0]-1,5)[1:]; i=0\n",
    "for n in some_frames:\n",
    "    ax=fig.add_subplot(221+i)\n",
    "    h=ax.imshow(Ib[int(n),...],cmap=plt.cm.gray,vmin=0,vmax=1)\n",
    "    plt.title(\"Frame %i, t=%.1f\" % (n,t[int(n)]))\n",
    "    plt.colorbar(h);\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207ea1f5-181c-4a1f-9e0b-2af69b5e7fcf",
   "metadata": {},
   "source": [
    "## Check time evolution\n",
    "For finding useful analysis period of the time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bfdcb7-ffa0-43cf-9fd3-ec214809e7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "if find_steady_start or find_steady_end:\n",
    "    t_ = time.time()\n",
    "    print(\"Averaging and integrating spatially...\");\n",
    "    \n",
    "    # Reslice near the nozzle to see time evolution\n",
    "    # Average over streamwise coordinates.\n",
    "    near_nozzle_profiles = np.nanmean(Ib,axis=-1).T\n",
    "    # Integrate over transverse coordinates\n",
    "    near_nozzle_integral = scipy.integrate.simpson(near_nozzle_profiles.T,x=y,axis=-1)\n",
    "    print(\" - elapsed time: %.1f s\" % (time.time()-t_));\n",
    "\n",
    "    # Use the integral data to find when the flow is 'active'\n",
    "    threshold = 0.95 # higher value means less time samples but lower std dev.\n",
    "    on = np.where(near_nozzle_integral > threshold*np.nanmax(near_nozzle_integral))[0]\n",
    "    if find_steady_start: t0=on[0]\n",
    "    else: t0=0\n",
    "    if find_steady_end: t1=on[-1]\n",
    "    else: t1=Ib.shape[0]-1\n",
    "else:\n",
    "    t0=0; t1=Ib.shape[0]-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22916525-cdbe-4e01-8ff4-f836eb722f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the time evolution near the nozzle\n",
    "\n",
    "if find_steady_start:\n",
    "    fig=plt.figure()\n",
    "    plt.suptitle(os.path.basename(source_images))\n",
    "    ax=fig.add_subplot(211)\n",
    "    plt.title(\"Time evolution near nozzle\")\n",
    "    plt.ylabel(\"Y [pixel]\")\n",
    "    plt.xlabel(\"Time [frame#]\")\n",
    "    h=ax.imshow(near_nozzle_profiles, cmap=plt.cm.gnuplot,vmin=0, aspect='auto')\n",
    "    plt.colorbar(h)\n",
    "    ax=fig.add_subplot(212)\n",
    "    ax.plot(t, near_nozzle_integral, lw=1)\n",
    "    plt.axvline(t[t0],c='k',lw=1,ls='--')\n",
    "    plt.axvline(t[t1],c='k',lw=1,ls='--')\n",
    "    plt.ylabel(\"Transverse integral\")\n",
    "    plt.xlabel(\"Time [frame#]\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65a4c72-4228-47fb-a1e5-ece42e78917e",
   "metadata": {},
   "source": [
    "## Save the usable part of the timeseries\n",
    "\n",
    "Write the data to a file so that we can separate the analysis of the data from this post processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d652ace1-7b8a-4df4-8f1e-82196f325f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "t_=time.time()\n",
    "grpName=\"frames_%i_%i\" % (t[t0],t[t1])\n",
    "filename = os.path.dirname(source_images)+\"_extinction.h5\"\n",
    "print(\"Writing to %s:\" % (filename))\n",
    "with h5py.File(filename, 'a') as H:\n",
    "    if grpName in H: \n",
    "        del H[grpName] # remove previously written group\n",
    "        print(' - replaced group ',grpName)\n",
    "    else:\n",
    "        print(' - created group ',grpName)\n",
    "    G=H.create_group(grpName)\n",
    "    G.create_dataset(\"time_frames\",data=t[t0:t1],compression='lzf')\n",
    "    G.create_dataset(\"x_pixel\",data=x,compression='lzf'); print(\" - wrote x\")\n",
    "    G.create_dataset(\"y_pixel\",data=y,compression='lzf'); print(\" - wrote y\")\n",
    "    G.create_dataset(\"bkgnd\",data=bkgnd,compression='lzf'); print(\" - wrote bkgnd\")\n",
    "    G.create_dataset(\"I\",data=Ib[t0:t1,...],compression='lzf'); print(\" - wrote I\")\n",
    "\n",
    "file_stats = os.stat(filename)\n",
    "print(\" - size now %.1f MB\" % (file_stats.st_size / (1024 * 1024)))\n",
    "print(\" - elapsed time: %.1f s\" % (time.time()-t_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be8c1ff-57f7-4962-8f75-2d282c1c4549",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Done.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mainenv",
   "language": "python",
   "name": "mainenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
